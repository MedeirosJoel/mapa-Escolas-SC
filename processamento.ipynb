{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import os.path\n",
    "from myConfig import KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_list(data):\n",
    "    result = list()\n",
    "    for item in data:\n",
    "        result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_100_elements(x: list):\n",
    "    \"\"\"Transforma uma grande lista, em uma lista de listas de 100 elementos em cada posição da respectiva lista.\n",
    "    \"\"\"\n",
    "    quantidade_requisicoes = len(x)//100\n",
    "    lista_separada = []\n",
    "\n",
    "    for i in range(0, quantidade_requisicoes+1):\n",
    "        \n",
    "        if i == quantidade_requisicoes:\n",
    "            inicio = i*100\n",
    "            fim = len(x)\n",
    "        else:\n",
    "            inicio = i*100\n",
    "            fim = ((i+1)*100)\n",
    "\n",
    "        lista_separada.append(x[inicio:fim])\n",
    "\n",
    "    return lista_separada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(x):\n",
    "    x = str(x)\n",
    "    return re.sub(r\"\\s+\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LatLong(enderecos: list):\n",
    "    \n",
    "    url = f'http://www.mapquestapi.com/geocoding/v1/batch?key={KEY}'\n",
    "\n",
    "    locations = transform_into_list(enderecos)\n",
    "    locations = list(map(remove_spaces, locations))\n",
    "    \n",
    "    data = {\n",
    "        \"locations\": locations,\n",
    "        \"options\": {\n",
    "            \"maxResults\": -1,\n",
    "            \"thumbMaps\": True,\n",
    "            \"ignoreLatLngInput\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = CaseInsensitiveDict()    \n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=json.dumps(data))\n",
    "    print(response, end='') \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_LatLng(data):\n",
    "    final_resposta = []\n",
    "    for resposta in data:\n",
    "        resposta = resposta.json()\n",
    "\n",
    "        for element in resposta['results']:\n",
    "            temp = [\n",
    "                element['providedLocation']['street'],\n",
    "                element['locations'][0]['latLng']['lat'],\n",
    "                element['locations'][0]['latLng']['lng']\n",
    "            ]\n",
    "            final_resposta.append(temp)\n",
    "            \n",
    "    return final_resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(filepatch:str):\n",
    "    return os.path.exists(filepatch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "depencia = ['estaduais', 'federais', 'municipais', 'privadas']\n",
    "tabelas = {}\n",
    "for nome in depencia:\n",
    "    tabelas['df_', nome] = pd.read_excel(f'raw_xlsx/{nome}.xlsx', header=4)\n",
    "\n",
    "df = pd.concat(tabelas, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpa dados, converte organiza e cria a coluna endereço completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas, e renomear\n",
    "unnamed_colluns = ['Unnamed: 11',\n",
    "                'Unnamed: 12',\n",
    "                'Unnamed: 13',\n",
    "                'Unnamed: 14',\n",
    "                'Unnamed: 15']\n",
    "\n",
    "rename_colluns = {\n",
    "    'Nº': 'num',\n",
    "    'município': 'municipio',\n",
    "    'Endereço': 'endereco'}\n",
    "    \n",
    "df = df.drop(unnamed_colluns, axis=1)\n",
    "df = df. rename(rename_colluns, axis=1)\n",
    "df['num'] = df['num'].astype('str')\n",
    "df['CEP'] = df['CEP'].astype('str') \n",
    "df['municipio'] = df['municipio'].str.strip()\n",
    "\n",
    "df['endereco_completo'] = df['endereco'] + ', ' \\\n",
    "                        + df['num'] + ' - ' \\\n",
    "                        + df['bairro'] + ', ' \\\n",
    "                        + df['municipio'] + \\\n",
    "                        ' - SC, '+ df['CEP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "centenas = split_100_elements(df['endereco_completo'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processo de busca de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carregando dados já processados.\n",
      "Dados carregados!\n"
     ]
    }
   ],
   "source": [
    "data = list()\n",
    "\n",
    "if not file_exists('data.pkl'):\n",
    "    for centena in centenas:\n",
    "        data.append(get_LatLong(centena))\n",
    "    \n",
    "    data = extract_LatLng(data)\n",
    "\n",
    "else:\n",
    "    print('carregando dados já processados.')\n",
    "    with open('data.pkl', 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    print('Dados carregados!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lng = [], []\n",
    "for dado in data:\n",
    "    lat.append(dado[1])\n",
    "    lng.append(dado[2])\n",
    "\n",
    "df['lat'] = lat\n",
    "df['lng'] =lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataframe.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ce8a19de8707bd499bac23c83523c7941807cf85c79c321c62cd133b8dec02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
